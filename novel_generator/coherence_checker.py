# coherence_checker.py
# -*- coding: utf-8 -*-
"""
è·¨ç« èŠ‚è¿è´¯æ€§éªŒè¯æ¨¡å—
ç”¨äºæ£€æŸ¥å¤šç« èŠ‚å°è¯´çš„æƒ…èŠ‚è¿ç»­æ€§ã€è§’è‰²ä¸€è‡´æ€§ã€è®¾å®šè¿è´¯æ€§ç­‰
"""

import re
import json
import logging
import os
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
from llm_adapters import create_llm_adapter
from novel_generator.chapter import load_character_name_registry

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

@dataclass
class CoherenceIssue:
    """è¿è´¯æ€§é—®é¢˜æ•°æ®ç»“æ„"""
    issue_type: str  # 'plot', 'character_name', 'character_trait', 'setting'
    severity: str    # 'high', 'medium', 'low'
    description: str
    location: str    # ç« èŠ‚å·å’Œæ®µè½ä½ç½®
    suggestion: str  # ä¿®å¤å»ºè®®
    chapters_involved: List[int]  # æ¶‰åŠçš„ç« èŠ‚å·

@dataclass
class CoherenceScore:
    """è¿è´¯æ€§åˆ†æ•°æ•°æ®ç»“æ„"""
    plot_continuity: float  # æƒ…èŠ‚è¿ç»­æ€§åˆ†æ•° (0-100)
    character_consistency: float  # è§’è‰²ä¸€è‡´æ€§åˆ†æ•° (0-100)
    setting_consistency: float  # è®¾å®šè¿è´¯æ€§åˆ†æ•° (0-100)
    overall_score: float  # æ€»ä½“åˆ†æ•° (0-100)

@dataclass
class CharacterInfo:
    """è§’è‰²ä¿¡æ¯æ•°æ®ç»“æ„"""
    name: str
    traits: Dict[str, str]  # ç‰¹å¾å­—å…¸ï¼šæ€§åˆ«ã€å¹´é¾„ã€å¤–è²Œã€æ€§æ ¼ç­‰
    first_appearance: int  # é¦–æ¬¡å‡ºç°çš„ç« èŠ‚å·
    appearances: List[int]  # å‡ºç°è¿‡çš„ç« èŠ‚å·

class CoherenceChecker:
    """è·¨ç« èŠ‚è¿è´¯æ€§æ£€æŸ¥å™¨"""

    def __init__(self, llm_config: Dict[str, Any], project_path: Optional[str] = None):
        """
        åˆå§‹åŒ–è¿è´¯æ€§æ£€æŸ¥å™¨

        Args:
            llm_config: LLMé…ç½®å­—å…¸ï¼ŒåŒ…å«api_key, base_url, model_nameç­‰
            project_path: é¡¹ç›®è·¯å¾„ï¼Œç”¨äºåŠ è½½è§’è‰²åå­—æ³¨å†Œè¡¨
        """
        self.llm_config = llm_config
        # æ·»åŠ é»˜è®¤timeoutå‚æ•°
        llm_config_with_timeout = {**llm_config, "timeout": llm_config.get("timeout", 600)}
        self.llm_adapter = create_llm_adapter(**llm_config_with_timeout)
        self.issues: List[CoherenceIssue] = []
        self.characters: Dict[str, CharacterInfo] = {}
        self.project_path = project_path

        # åŠ è½½è§’è‰²åå­—æ³¨å†Œè¡¨ï¼ˆä¸Story 3.1é›†æˆï¼‰
        self.character_name_registry = {}
        if project_path:
            self._load_character_registry()

    def _load_character_registry(self):
        """åŠ è½½è§’è‰²åå­—æ³¨å†Œè¡¨ï¼ˆä¸Story 3.1é›†æˆï¼‰"""
        try:
            registry_file = os.path.join(self.project_path, "character_names.json")
            if os.path.exists(registry_file):
                with open(registry_file, 'r', encoding='utf-8') as f:
                    self.character_name_registry = json.load(f)
                logger.info(f"å·²åŠ è½½è§’è‰²åå­—æ³¨å†Œè¡¨ï¼ŒåŒ…å« {len(self.character_name_registry)} ä¸ªè§’è‰²")
        except Exception as e:
            logger.error(f"åŠ è½½è§’è‰²åå­—æ³¨å†Œè¡¨å¤±è´¥: {e}")
            self.character_name_registry = {}

    def check_plot_continuity(self, chapter_n: str, chapter_n_minus_1: str,
                            chapter_n_num: int) -> Tuple[float, List[CoherenceIssue]]:
        """
        æ£€æŸ¥æƒ…èŠ‚è¿ç»­æ€§

        Args:
            chapter_n: ç¬¬Nç« å†…å®¹
            chapter_n_minus_1: ç¬¬N-1ç« å†…å®¹
            chapter_n_num: ç¬¬Nç« çš„ç« èŠ‚æ•°

        Returns:
            Tuple[åˆ†æ•°, é—®é¢˜åˆ—è¡¨]
        """
        prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹ä¸¤ä¸ªç« èŠ‚çš„æƒ…èŠ‚è¿ç»­æ€§:

ç¬¬{chapter_n_num-1}ç« æ‘˜è¦:
{self._extract_summary(chapter_n_minus_1)}

ç¬¬{chapter_n_num}ç« æ‘˜è¦:
{self._extract_summary(chapter_n)}

è¯„ä¼°æ ‡å‡†:
1. æƒ…èŠ‚æ˜¯å¦è‡ªç„¶å»¶ç»­?(0-100åˆ†)
2. æ˜¯å¦æœ‰çªå…€çš„è½¬æŠ˜æˆ–è·³è·ƒ?
3. æ•´ä½“è¿è´¯æ€§å¦‚ä½•?

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤:
{{
    "score": 85,
    "analysis": "æƒ…èŠ‚è‡ªç„¶è¿‡æ¸¡ï¼Œæ²¡æœ‰æ˜æ˜¾è·³è·ƒ",
    "issues": [
        {{
            "severity": "medium",
            "description": "ç¬¬{chapter_n_num}ç« å¼€å¤´ç•¥æ˜¾çªå…€",
            "suggestion": "å»ºè®®å¢åŠ è¿‡æ¸¡å¥ï¼Œæ‰¿æ¥ä¸Šä¸€ç« ç»“å°¾"
        }}
    ]
}}"""

        try:
            response = self.llm_adapter.invoke(prompt)
            result = self._parse_json_response(response)

            score = result.get('score', 80)
            issues = []

            for issue_data in result.get('issues', []):
                issue = CoherenceIssue(
                    issue_type='plot',
                    severity=issue_data.get('severity', 'medium'),
                    description=issue_data.get('description', ''),
                    location=f"ç¬¬{chapter_n_num}ç« ",
                    suggestion=issue_data.get('suggestion', ''),
                    chapters_involved=[chapter_n_num-1, chapter_n_num]
                )
                issues.append(issue)

            return score, issues

        except Exception as e:
            logger.error(f"æƒ…èŠ‚è¿ç»­æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return 70.0, [CoherenceIssue(
                issue_type='plot',
                severity='medium',
                description=f"æ£€æŸ¥å¤±è´¥: {str(e)}",
                location=f"ç¬¬{chapter_n_num}ç« ",
                suggestion="è¯·æ‰‹åŠ¨æ£€æŸ¥æƒ…èŠ‚è¿è´¯æ€§",
                chapters_involved=[chapter_n_num-1, chapter_n_num]
            )]

    def extract_character_names(self, chapter_text: str) -> List[str]:
        """
        æå–ç« èŠ‚ä¸­çš„è§’è‰²åå­—

        Args:
            chapter_text: ç« èŠ‚æ–‡æœ¬

        Returns:
            è§’è‰²åå­—åˆ—è¡¨
        """
        # ä¸­æ–‡äººåæ¨¡å¼ï¼šå§“(1-2å­—)+å(1-2å­—)
        chinese_name_pattern = r'[\u4e00-\u9fa5]{2,4}(?=[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€‹ã€Šã€‹\\s])'

        # è¥¿å¼äººåæ¨¡å¼ï¼šé¦–å­—æ¯å¤§å†™ + 2-15ä¸ªå­—æ¯
        western_name_pattern = r'\b[A-Z][a-z]{1,15}\b(?=[,.!?;:\s"\'()\[\]])'

        # æå–æ‰€æœ‰å¯èƒ½çš„åå­—
        chinese_names = re.findall(chinese_name_pattern, chapter_text)
        western_names = re.findall(western_name_pattern, chapter_text)

        # è¿‡æ»¤å¸¸è§è¯æ±‡
        common_words = {'æˆ‘ä»¬', 'ä»–ä»¬', 'å¥¹ä»¬', 'ä½ ä»¬', 'è‡ªå·±', 'å¤§å®¶', 'æœ‰äºº', 'æ²¡äºº',
                       'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'å› ä¸º', 'æ‰€ä»¥', 'ä½†æ˜¯',
                       'The', 'This', 'That', 'He', 'She', 'It', 'They', 'What', 'When'}

        all_names = []
        for name in chinese_names + western_names:
            if name not in common_words and len(name) >= 2:
                all_names.append(name)

        # å»é‡å¹¶ä¿æŒé¡ºåº
        seen = set()
        unique_names = []
        for name in all_names:
            if name not in seen:
                seen.add(name)
                unique_names.append(name)

        return unique_names

    def normalize_name(self, name: str) -> str:
        """
        åå­—æ ‡å‡†åŒ–å¤„ç†ï¼Œå¤„ç†åå­—å˜ä½“

        Args:
            name: åŸå§‹åå­—

        Returns:
            æ ‡å‡†åŒ–åçš„åå­—
        """
        name = name.strip()

        # å¤„ç†å¸¸è§ç§°è°“å˜ä½“
        title_mappings = {
            'å…ˆç”Ÿ': '',
            'å¥³å£«': '',
            'å°å§': '',
            'è€å¸ˆ': '',
            'åŒ»ç”Ÿ': '',
            'æ•™æˆ': '',
            'Mr.': '',
            'Mrs.': '',
            'Ms.': '',
            'Dr.': '',
            'Prof.': ''
        }

        for title, replacement in title_mappings.items():
            if name.endswith(title):
                name = name[:-len(title)] + replacement
                break

        # å¤„ç†ç®€ç§°å˜ä½“ï¼ˆå¦‚"å°æ" -> "ææ˜"ï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ˜ å°„
        surname_prefix_mappings = {
            'å°': '',
            'è€': '',
            'é˜¿': ''
        }

        for prefix, replacement in surname_prefix_mappings.items():
            if name.startswith(prefix) and len(name) == 3:
                # ç®€å•å¤„ç†ï¼šå¦‚æœæ˜¯"å°æ"è¿™æ ·çš„æ ¼å¼ï¼Œæš‚æ—¶ä¿ç•™åŸå
                # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦è§’è‰²æ³¨å†Œè¡¨æ¥æ˜ å°„
                pass

        return name.strip()

    def check_character_name_consistency(self, chapters: List[str]) -> Tuple[float, List[CoherenceIssue]]:
        """
        æ£€æŸ¥è§’è‰²åå­—ä¸€è‡´æ€§ï¼ˆä¸Story 3.1é›†æˆï¼‰

        Args:
            chapters: æ‰€æœ‰ç« èŠ‚å†…å®¹åˆ—è¡¨

        Returns:
            Tuple[ä¸€è‡´æ€§åˆ†æ•°, é—®é¢˜åˆ—è¡¨]
        """
        character_appearances = {}  # {è§’è‰²å: {ç« èŠ‚å·: [å‡ºç°æ¬¡æ•°]}}

        # æ”¶é›†æ¯ç« çš„è§’è‰²åå­—
        for i, chapter in enumerate(chapters, 1):
            names = self.extract_character_names(chapter)
            for name in names:
                normalized_name = self.normalize_name(name)
                if normalized_name not in character_appearances:
                    character_appearances[normalized_name] = {}
                if i not in character_appearances[normalized_name]:
                    character_appearances[normalized_name][i] = 0
                character_appearances[normalized_name][i] += 1

        # æ£€æŸ¥åå­—ä¸€è‡´æ€§
        issues = []
        total_characters = len(character_appearances)
        consistent_characters = 0

        for character, appearances in character_appearances.items():
            # å¦‚æœè§’è‰²åªåœ¨å•ä¸ªç« èŠ‚å‡ºç°ï¼Œè·³è¿‡ä¸€è‡´æ€§æ£€æŸ¥
            if len(appearances) < 2:
                consistent_characters += 1
                continue

            # æ£€æŸ¥æ˜¯å¦æœ‰åå­—å˜ä½“
            all_names_in_chapters = set()
            for chapter_idx, chapter in enumerate(chapters, 1):
                if chapter_idx in appearances:
                    names_in_chapter = self.extract_character_names(chapter)
                    normalized_names = [self.normalize_name(name) for name in names_in_chapter]
                    all_names_in_chapters.update(normalized_names)

            # å¦‚æœå­˜åœ¨å¤šä¸ªä¸åŒçš„æ ‡å‡†åŒ–åå­—ï¼Œå¯èƒ½å­˜åœ¨ä¸€è‡´æ€§é—®é¢˜
            if len(all_names_in_chapters) > 1:
                # æ£€æŸ¥è§’è‰²åå­—æ³¨å†Œè¡¨æ˜¯å¦æœ‰ç›¸å…³ä¿¡æ¯
                registry_info = self._check_character_registry(character, all_names_in_chapters)

                severity = 'medium'
                if registry_info['is_registered']:
                    # å¦‚æœæ˜¯æ³¨å†Œè¡¨ä¸­çš„è§’è‰²ï¼Œé—®é¢˜æ›´ä¸¥é‡
                    severity = 'high'
                    description = f"å·²æ³¨å†Œè§’è‰²'{character}'çš„åå­—å‡ºç°ä¸ä¸€è‡´: {', '.join(all_names_in_chapters)}"
                    suggestion = f"åº”è¯¥ä½¿ç”¨æ³¨å†Œè¡¨ä¸­çš„åå­—: {registry_info['registered_name']}"
                else:
                    description = f"è§’è‰²'{character}'çš„åå­—åœ¨ä¸åŒç« èŠ‚ä¸­å­˜åœ¨å˜ä½“: {', '.join(all_names_in_chapters)}"
                    suggestion = "å»ºè®®ç»Ÿä¸€è§’è‰²åå­—ï¼Œæˆ–ç¡®è®¤æ˜¯å¦ä¸ºä¸åŒè§’è‰²"

                issue = CoherenceIssue(
                    issue_type='character_name',
                    severity=severity,
                    description=description,
                    location=f"ç¬¬{min(appearances.keys())}-{max(appearances.keys())}ç« ",
                    suggestion=suggestion,
                    chapters_involved=list(appearances.keys())
                )
                issues.append(issue)
            else:
                consistent_characters += 1

        # æ£€æŸ¥æ³¨å†Œè¡¨ä¸­çš„è§’è‰²æ˜¯å¦åœ¨æ–‡æœ¬ä¸­æ­£ç¡®ä½¿ç”¨
        registry_issues = self._check_registry_usage(chapters)
        issues.extend(registry_issues)

        # è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°
        if total_characters == 0:
            score = 100.0
        else:
            score = (consistent_characters / total_characters) * 100

        return score, issues

    def _check_character_registry(self, character: str, found_names: set) -> Dict[str, Any]:
        """
        æ£€æŸ¥è§’è‰²åå­—æ³¨å†Œè¡¨ä¸­çš„ä¿¡æ¯

        Args:
            character: æ ‡å‡†åŒ–çš„è§’è‰²å
            found_names: åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°çš„åå­—å˜ä½“

        Returns:
            æ³¨å†Œè¡¨ä¿¡æ¯å­—å…¸
        """
        result = {
            'is_registered': False,
            'registered_name': None,
            'registry_variants': []
        }

        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„æ³¨å†Œè§’è‰²
        for registered_id, registered_name in self.character_name_registry.items():
            # æ£€æŸ¥æ ‡å‡†åŒ–åçš„åå­—æ˜¯å¦åŒ¹é…
            if self.normalize_name(registered_name) == character:
                result['is_registered'] = True
                result['registered_name'] = registered_name
                break

        return result

    def _check_registry_usage(self, chapters: List[str]) -> List[CoherenceIssue]:
        """
        æ£€æŸ¥æ³¨å†Œè¡¨ä¸­çš„è§’è‰²åå­—æ˜¯å¦åœ¨æ–‡æœ¬ä¸­æ­£ç¡®ä½¿ç”¨

        Args:
            chapters: æ‰€æœ‰ç« èŠ‚å†…å®¹åˆ—è¡¨

        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        issues = []

        for registered_id, registered_name in self.character_name_registry.items():
            found_in_chapters = []

            # æ£€æŸ¥æ¯ä¸ªç« èŠ‚æ˜¯å¦åŒ…å«è¯¥è§’è‰²
            for i, chapter in enumerate(chapters, 1):
                names_in_chapter = self.extract_character_names(chapter)
                normalized_names = [self.normalize_name(name) for name in names_in_chapter]

                if self.normalize_name(registered_name) in normalized_names:
                    found_in_chapters.append(i)

            # å¦‚æœæ³¨å†Œè§’è‰²åœ¨å¤šç« èŠ‚ä¸­å‡ºç°ï¼Œæ£€æŸ¥åå­—æ˜¯å¦ä¸€è‡´
            if len(found_in_chapters) > 1:
                # æ£€æŸ¥å®é™…ä½¿ç”¨çš„åå­—æ˜¯å¦ä¸æ³¨å†Œè¡¨ä¸€è‡´
                name_variations = set()
                for chapter_idx in found_in_chapters:
                    names_in_chapter = self.extract_character_names(chapters[chapter_idx - 1])
                    for name in names_in_chapter:
                        if self.normalize_name(name) == self.normalize_name(registered_name):
                            name_variations.add(name)

                if len(name_variations) > 1:
                    issue = CoherenceIssue(
                        issue_type='character_name',
                        severity='high',
                        description=f"æ³¨å†Œè§’è‰²'{registered_name}'åœ¨æ–‡æœ¬ä¸­æœ‰å¤šç§å†™æ³•: {', '.join(name_variations)}",
                        location=f"ç¬¬{min(found_in_chapters)}-{max(found_in_chapters)}ç« ",
                        suggestion=f"åº”è¯¥ç»Ÿä¸€ä½¿ç”¨æ³¨å†Œè¡¨ä¸­çš„åå­—: {registered_name}",
                        chapters_involved=found_in_chapters
                    )
                    issues.append(issue)

        return issues

    def extract_character_traits(self, chapter_text: str, character_name: str) -> Dict[str, str]:
        """
        ä»ç« èŠ‚æ–‡æœ¬ä¸­æå–è§’è‰²çš„ç‰¹å¾

        Args:
            chapter_text: ç« èŠ‚æ–‡æœ¬
            character_name: è§’è‰²åå­—

        Returns:
            è§’è‰²ç‰¹å¾å­—å…¸
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–è§’è‰²"{character_name}"çš„ç‰¹å¾ä¿¡æ¯:

æ–‡æœ¬å†…å®¹:
{chapter_text[:2000]}  # é™åˆ¶é•¿åº¦ä»¥æ§åˆ¶tokenæ¶ˆè€—

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼Œå¦‚æœæŸé¡¹ä¿¡æ¯æœªæåŠè¯·ç•™ç©º:
{{
    "gender": "",
    "age": "",
    "appearance": "",
    "personality": "",
    "occupation": "",
    "background": ""
}}"""

        try:
            response = self.llm_adapter.invoke(prompt)
            result = self._parse_json_response(response)

            # è¿‡æ»¤ç©ºå€¼
            traits = {}
            for key, value in result.items():
                if value and value.strip():
                    traits[key] = value.strip()

            return traits

        except Exception as e:
            logger.error(f"ç‰¹å¾æå–å¤±è´¥: {e}")
            return {}

    def check_character_trait_consistency(self, chapters: List[str]) -> Tuple[float, List[CoherenceIssue]]:
        """
        æ£€æŸ¥è§’è‰²ç‰¹å¾ä¸€è‡´æ€§

        Args:
            chapters: æ‰€æœ‰ç« èŠ‚å†…å®¹åˆ—è¡¨

        Returns:
            Tuple[ä¸€è‡´æ€§åˆ†æ•°, é—®é¢˜åˆ—è¡¨]
        """
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰è§’è‰²åå­—
        all_characters = set()
        for chapter in chapters:
            names = self.extract_character_names(chapter)
            all_characters.update([self.normalize_name(name) for name in names])

        issues = []
        character_consistency_scores = []

        for character in all_characters:
            character_traits = {}  # {ç« èŠ‚å·: ç‰¹å¾å­—å…¸}

            # æå–æ¯ç« ä¸­çš„è§’è‰²ç‰¹å¾
            for i, chapter in enumerate(chapters, 1):
                if character in [self.normalize_name(name) for name in self.extract_character_names(chapter)]:
                    traits = self.extract_character_traits(chapter, character)
                    if traits:  # åªä¿å­˜æœ‰ç‰¹å¾çš„ç« èŠ‚
                        character_traits[i] = traits

            # å¦‚æœè§’è‰²åœ¨å¤šç« èŠ‚ä¸­æœ‰ç‰¹å¾æè¿°ï¼Œæ£€æŸ¥ä¸€è‡´æ€§
            if len(character_traits) > 1:
                consistency_score = self._evaluate_trait_consistency(character, character_traits)
                character_consistency_scores.append(consistency_score)

                if consistency_score < 80:  # ä¸€è‡´æ€§é˜ˆå€¼
                    # ç”Ÿæˆå…·ä½“çš„ä¸ä¸€è‡´é—®é¢˜
                    inconsistency_details = self._find_trait_inconsistencies(character, character_traits)
                    for detail in inconsistency_details:
                        issue = CoherenceIssue(
                            issue_type='character_trait',
                            severity='high' if consistency_score < 60 else 'medium',
                            description=detail['description'],
                            location=detail['location'],
                            suggestion=detail['suggestion'],
                            chapters_involved=list(character_traits.keys())
                        )
                        issues.append(issue)

        # è®¡ç®—æ€»ä½“è§’è‰²ä¸€è‡´æ€§åˆ†æ•°
        if character_consistency_scores:
            avg_score = sum(character_consistency_scores) / len(character_consistency_scores)
        else:
            avg_score = 100.0  # æ²¡æœ‰éœ€è¦æ£€æŸ¥çš„è§’è‰²

        return avg_score, issues

    def extract_story_setting(self, chapter_text: str) -> Dict[str, str]:
        """
        æå–æ•…äº‹è®¾å®šä¿¡æ¯

        Args:
            chapter_text: ç« èŠ‚æ–‡æœ¬

        Returns:
            è®¾å®šä¿¡æ¯å­—å…¸
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹ç« èŠ‚ä¸­æå–æ•…äº‹è®¾å®šä¿¡æ¯:

ç« èŠ‚å†…å®¹:
{chapter_text[:2000]}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼Œå¦‚æœæŸé¡¹ä¿¡æ¯æœªæåŠè¯·ç•™ç©º:
{{
    "time_period": "",
    "world_type": "",
    "location": "",
    "technology_level": "",
    "social_structure": ""
}}"""

        try:
            response = self.llm_adapter.invoke(prompt)
            result = self._parse_json_response(response)

            # è¿‡æ»¤ç©ºå€¼
            setting = {}
            for key, value in result.items():
                if value and value.strip():
                    setting[key] = value.strip()

            return setting

        except Exception as e:
            logger.error(f"è®¾å®šæå–å¤±è´¥: {e}")
            return {}

    def check_setting_consistency(self, chapters: List[str]) -> Tuple[float, List[CoherenceIssue]]:
        """
        æ£€æŸ¥æ•…äº‹è®¾å®šè¿è´¯æ€§

        Args:
            chapters: æ‰€æœ‰ç« èŠ‚å†…å®¹åˆ—è¡¨

        Returns:
            Tuple[è¿è´¯æ€§åˆ†æ•°, é—®é¢˜åˆ—è¡¨]
        """
        settings = {}  # {ç« èŠ‚å·: è®¾å®šå­—å…¸}

        # æå–æ¯ç« çš„è®¾å®šä¿¡æ¯
        for i, chapter in enumerate(chapters, 1):
            setting = self.extract_story_setting(chapter)
            if setting:  # åªä¿å­˜æœ‰è®¾å®šä¿¡æ¯çš„ç« èŠ‚
                settings[i] = setting

        issues = []
        consistency_scores = []

        # æ£€æŸ¥å„ä¸ªè®¾å®šç»´åº¦çš„ä¸€è‡´æ€§
        setting_dimensions = ['time_period', 'world_type', 'location', 'technology_level', 'social_structure']

        for dimension in setting_dimensions:
            dimension_values = {}  # {å€¼: [ç« èŠ‚å·åˆ—è¡¨]}

            for chapter_num, setting in settings.items():
                if dimension in setting and setting[dimension]:
                    value = setting[dimension]
                    if value not in dimension_values:
                        dimension_values[value] = []
                    dimension_values[value].append(chapter_num)

            # å¦‚æœæŸä¸ªç»´åº¦æœ‰å¤šç§ä¸åŒçš„å€¼ï¼Œå¯èƒ½å­˜åœ¨ä¸ä¸€è‡´
            if len(dimension_values) > 1:
                # ä½¿ç”¨LLMè¯„ä¼°è¿™äº›å·®å¼‚æ˜¯å¦åˆç†
                values_text = '\n'.join([f"- {v}: ç¬¬{', '.join(map(str, chapters))}ç« "
                                       for v, chapters in dimension_values.items()])

                prompt = f"""ä»¥ä¸‹è®¾å®šç»´åº¦åœ¨ä¸åŒç« èŠ‚ä¸­æœ‰ä¸åŒçš„æè¿°:

è®¾å®šç»´åº¦: {dimension}
ä¸åŒæè¿°:
{values_text}

è¯·åˆ¤æ–­è¿™äº›å·®å¼‚æ˜¯å¦åˆç†æˆ–ä¸ä¸€è‡´ï¼ŒæŒ‰JSONæ ¼å¼å›å¤:
{{
    "is_consistent": true/false,
    "score": 85,
    "analysis": "åˆ†æè¯´æ˜",
    "issues": ["é—®é¢˜æè¿°1", "é—®é¢˜æè¿°2"]
}}"""

                try:
                    response = self.llm_adapter.invoke(prompt)
                    result = self._parse_json_response(response)

                    if not result.get('is_consistent', True):
                        score = result.get('score', 70)
                        consistency_scores.append(score)

                        for issue_desc in result.get('issues', []):
                            issue = CoherenceIssue(
                                issue_type='setting',
                                severity='medium',
                                description=f"è®¾å®š'{dimension}'ä¸ä¸€è‡´: {issue_desc}",
                                location=f"ç¬¬{min([ch for vals in dimension_values.values() for ch in vals])}-{max([ch for vals in dimension_values.values() for ch in vals])}ç« ",
                                suggestion="å»ºè®®ç»Ÿä¸€è®¾å®šæè¿°ï¼Œæˆ–æä¾›åˆç†çš„è§£é‡Š",
                                chapters_involved=list(settings.keys())
                            )
                            issues.append(issue)
                    else:
                        consistency_scores.append(95)  # è®¤ä¸ºä¸€è‡´

                except Exception as e:
                    logger.error(f"è®¾å®šä¸€è‡´æ€§è¯„ä¼°å¤±è´¥: {e}")
                    consistency_scores.append(75)

        # è®¡ç®—æ€»ä½“è®¾å®šä¸€è‡´æ€§åˆ†æ•°
        if consistency_scores:
            avg_score = sum(consistency_scores) / len(consistency_scores)
        else:
            avg_score = 100.0  # æ²¡æœ‰éœ€è¦æ£€æŸ¥çš„è®¾å®š

        return avg_score, issues

    def calculate_overall_scores(self, plot_score: float, character_score: float, setting_score: float) -> CoherenceScore:
        """
        è®¡ç®—æ€»ä½“è¿è´¯æ€§åˆ†æ•°

        Args:
            plot_score: æƒ…èŠ‚è¿è´¯æ€§åˆ†æ•°
            character_score: è§’è‰²ä¸€è‡´æ€§åˆ†æ•°
            setting_score: è®¾å®šè¿è´¯æ€§åˆ†æ•°

        Returns:
            å®Œæ•´çš„è¿è´¯æ€§åˆ†æ•°å¯¹è±¡
        """
        # åŠ æƒå¹³å‡ (å‚è€ƒDev Notesä¸­çš„æƒé‡)
        overall_score = (plot_score * 0.4 + character_score * 0.3 + setting_score * 0.3)

        return CoherenceScore(
            plot_continuity=plot_score,
            character_consistency=character_score,
            setting_consistency=setting_score,
            overall_score=overall_score
        )

    def generate_quality_report(self, scores: CoherenceScore, issues: List[CoherenceIssue]) -> str:
        """
        ç”Ÿæˆè´¨é‡æŠ¥å‘Š

        Args:
            scores: è¿è´¯æ€§åˆ†æ•°
            issues: é—®é¢˜åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„è´¨é‡æŠ¥å‘Šæ–‡æœ¬
        """
        report = f"""# å°è¯´è¿è´¯æ€§æ£€æŸ¥æŠ¥å‘Š

**æ€»ä½“è´¨é‡åˆ†æ•°: {scores.overall_score:.1f}/100**

## æƒ…èŠ‚è¿è´¯åº¦: {scores.plot_continuity:.1f}/100 {'âœ…' if scores.plot_continuity >= 80 else 'âš ï¸' if scores.plot_continuity >= 60 else 'âŒ'}
"""

        # æŒ‰ç±»å‹åˆ†ç»„é—®é¢˜
        plot_issues = [issue for issue in issues if issue.issue_type == 'plot']
        character_name_issues = [issue for issue in issues if issue.issue_type == 'character_name']
        character_trait_issues = [issue for issue in issues if issue.issue_type == 'character_trait']
        setting_issues = [issue for issue in issues if issue.issue_type == 'setting']

        # æƒ…èŠ‚é—®é¢˜è¯¦æƒ…
        if plot_issues:
            report += f"\n**å‘ç°{len(plot_issues)}ä¸ªæƒ…èŠ‚é—®é¢˜**:\n"
            for issue in plot_issues:
                report += f"- {issue.description} (ç¬¬{', '.join(map(str, issue.chapters_involved))}ç« )\n"
                report += f"  å»ºè®®: {issue.suggestion}\n"
        else:
            report += "- æœªå‘ç°æ˜æ˜¾æƒ…èŠ‚è¿è´¯æ€§é—®é¢˜\n"

        # è§’è‰²ä¸€è‡´æ€§è¯¦æƒ…
        report += f"\n## è§’è‰²ä¸€è‡´æ€§: {scores.character_consistency:.1f}/100 {'âœ…' if scores.character_consistency >= 80 else 'âš ï¸' if scores.character_consistency >= 60 else 'âŒ'}\n"

        total_character_issues = len(character_name_issues) + len(character_trait_issues)
        if total_character_issues > 0:
            report += f"**å‘ç°{total_character_issues}ä¸ªè§’è‰²é—®é¢˜**:\n"

            for issue in character_name_issues:
                report += f"- è§’è‰²åå­—ä¸ä¸€è‡´: {issue.description}\n"
                report += f"  ä½ç½®: {issue.location}\n"
                report += f"  å»ºè®®: {issue.suggestion}\n"

            for issue in character_trait_issues:
                severity_icon = "ğŸ”´" if issue.severity == 'high' else "ğŸŸ¡"
                report += f"- {severity_icon} è§’è‰²ç‰¹å¾ä¸ä¸€è‡´: {issue.description}\n"
                report += f"  ä½ç½®: {issue.location}\n"
                report += f"  å»ºè®®: {issue.suggestion}\n"
        else:
            report += "- è§’è‰²åå­—å’Œç‰¹å¾ä¿æŒä¸€è‡´\n"

        # è®¾å®šè¿è´¯æ€§è¯¦æƒ…
        report += f"\n## è®¾å®šè¿è´¯åº¦: {scores.setting_consistency:.1f}/100 {'âœ…' if scores.setting_consistency >= 80 else 'âš ï¸' if scores.setting_consistency >= 60 else 'âŒ'}\n"

        if setting_issues:
            report += f"**å‘ç°{len(setting_issues)}ä¸ªè®¾å®šé—®é¢˜**:\n"
            for issue in setting_issues:
                report += f"- {issue.description}\n"
                report += f"  ä½ç½®: {issue.location}\n"
                report += f"  å»ºè®®: {issue.suggestion}\n"
        else:
            report += "- æ•…äº‹è®¾å®šä¿æŒä¸€è‡´\n"

        # æ€»ä½“å»ºè®®
        report += "\n## å»ºè®®\n"
        if issues:
            high_priority_issues = [issue for issue in issues if issue.severity == 'high']
            if high_priority_issues:
                report += "### é«˜ä¼˜å…ˆçº§é—®é¢˜\n"
                for issue in high_priority_issues:
                    report += f"1. {issue.description}\n"
                    report += f"   å»ºè®®: {issue.suggestion}\n"

            report += "\n### æ”¹è¿›å»ºè®®\n"
            report += "1. é‡ç‚¹å…³æ³¨è§’è‰²ç‰¹å¾çš„åˆç†æ¼”è¿›\n"
            report += "2. ç¡®ä¿æƒ…èŠ‚è¿‡æ¸¡çš„è‡ªç„¶æ€§\n"
            report += "3. ç»´æŠ¤æ•…äº‹è®¾å®šçš„ç»Ÿä¸€æ€§\n"
        else:
            report += "ğŸ‰ å°è¯´è¿è´¯æ€§è‰¯å¥½ï¼Œæœªå‘ç°é‡å¤§é—®é¢˜ï¼\n"

        return report

    def run_coherence_check(self, chapters: List[str]) -> Tuple[CoherenceScore, List[CoherenceIssue], str]:
        """
        è¿è¡Œå®Œæ•´çš„è¿è´¯æ€§æ£€æŸ¥

        Args:
            chapters: æ‰€æœ‰ç« èŠ‚å†…å®¹åˆ—è¡¨

        Returns:
            Tuple[åˆ†æ•°å¯¹è±¡, é—®é¢˜åˆ—è¡¨, è´¨é‡æŠ¥å‘Š]
        """
        logger.info(f"å¼€å§‹å¯¹{len(chapters)}ä¸ªç« èŠ‚è¿›è¡Œè¿è´¯æ€§æ£€æŸ¥")

        all_issues = []

        # 1. æ£€æŸ¥æƒ…èŠ‚è¿ç»­æ€§
        plot_scores = []
        for i in range(1, len(chapters)):
            score, issues = self.check_plot_continuity(chapters[i], chapters[i-1], i+1)
            plot_scores.append(score)
            all_issues.extend(issues)

        avg_plot_score = sum(plot_scores) / len(plot_scores) if plot_scores else 100.0

        # 2. æ£€æŸ¥è§’è‰²åå­—ä¸€è‡´æ€§
        character_name_score, name_issues = self.check_character_name_consistency(chapters)
        all_issues.extend(name_issues)

        # 3. æ£€æŸ¥è§’è‰²ç‰¹å¾ä¸€è‡´æ€§
        character_trait_score, trait_issues = self.check_character_trait_consistency(chapters)
        all_issues.extend(trait_issues)

        # åˆå¹¶è§’è‰²ä¸€è‡´æ€§åˆ†æ•°
        overall_character_score = (character_name_score + character_trait_score) / 2

        # 4. æ£€æŸ¥è®¾å®šè¿è´¯æ€§
        setting_score, setting_issues = self.check_setting_consistency(chapters)
        all_issues.extend(setting_issues)

        # 5. è®¡ç®—æ€»ä½“åˆ†æ•°
        scores = self.calculate_overall_scores(avg_plot_score, overall_character_score, setting_score)

        # 6. ç”Ÿæˆè´¨é‡æŠ¥å‘Š
        report = self.generate_quality_report(scores, all_issues)

        logger.info(f"è¿è´¯æ€§æ£€æŸ¥å®Œæˆ - æ€»ä½“åˆ†æ•°: {scores.overall_score:.1f}, å‘ç°é—®é¢˜: {len(all_issues)}ä¸ª")

        return scores, all_issues, report

    # ============== è¾…åŠ©æ–¹æ³• ==============

    def _extract_summary(self, chapter_text: str) -> str:
        """æå–ç« èŠ‚æ‘˜è¦"""
        # ç®€å•å®ç°ï¼šå–å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
        # å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„æ‘˜è¦æå–ç®—æ³•
        return chapter_text[:500] + "..." if len(chapter_text) > 500 else chapter_text

    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """è§£æLLMçš„JSONå“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            return json.loads(response)
        except json.JSONDecodeError:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except json.JSONDecodeError:
                    pass

            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›é»˜è®¤ç»“æ„
            logger.warning(f"æ— æ³•è§£æJSONå“åº”: {response}")
            return {}

    def _evaluate_trait_consistency(self, character: str, traits_by_chapter: Dict[int, Dict[str, str]]) -> float:
        """è¯„ä¼°è§’è‰²ç‰¹å¾ä¸€è‡´æ€§"""
        if len(traits_by_chapter) < 2:
            return 100.0

        # æ„å»ºæ£€æŸ¥æç¤º
        traits_text = []
        for chapter_num, traits in traits_by_chapter.items():
            traits_str = ', '.join([f"{k}: {v}" for k, v in traits.items()])
            traits_text.append(f"ç¬¬{chapter_num}ç« : {traits_str}")

        prompt = f"""è¯·è¯„ä¼°è§’è‰²"{character}"åœ¨ä¸åŒç« èŠ‚ä¸­çš„ç‰¹å¾ä¸€è‡´æ€§:

{chr(10).join(traits_text)}

è¯·è¯„ä¼°ç‰¹å¾æ˜¯å¦ä¸€è‡´æˆ–åˆç†æ¼”è¿›ï¼ŒæŒ‰JSONæ ¼å¼å›å¤:
{{
    "score": 85,
    "analysis": "ç‰¹å¾æè¿°åŸºæœ¬ä¸€è‡´ï¼Œå¹´é¾„å˜åŒ–åˆç†"
}}"""

        try:
            response = self.llm_adapter.invoke(prompt)
            result = self._parse_json_response(response)
            return float(result.get('score', 75))
        except Exception as e:
            logger.error(f"ç‰¹å¾ä¸€è‡´æ€§è¯„ä¼°å¤±è´¥: {e}")
            return 70.0

    def _find_trait_inconsistencies(self, character: str, traits_by_chapter: Dict[int, Dict[str, str]]) -> List[Dict[str, str]]:
        """æ‰¾åˆ°å…·ä½“çš„ç‰¹å¾ä¸ä¸€è‡´é—®é¢˜"""
        inconsistencies = []

        # æ”¶é›†æ‰€æœ‰ç‰¹å¾ç»´åº¦
        all_traits = set()
        for traits in traits_by_chapter.values():
            all_traits.update(traits.keys())

        # æ£€æŸ¥æ¯ä¸ªç»´åº¦çš„ä¸ä¸€è‡´
        for trait in all_traits:
            values_by_chapter = {}
            for chapter_num, traits in traits_by_chapter.items():
                if trait in traits:
                    value = traits[trait]
                    if value not in values_by_chapter:
                        values_by_chapter[value] = []
                    values_by_chapter[value].append(chapter_num)

            # å¦‚æœåŒä¸€ä¸ªç‰¹å¾æœ‰ä¸åŒçš„å€¼ï¼Œå¯èƒ½å­˜åœ¨ä¸ä¸€è‡´
            if len(values_by_chapter) > 1:
                chapters_list = [ch for vals in values_by_chapter.values() for ch in vals]
                inconsistencies.append({
                    'description': f"è§’è‰²'{character}'çš„{trait}åœ¨ä¸åŒç« èŠ‚ä¸­æè¿°ä¸ä¸€è‡´",
                    'location': f"ç¬¬{min(chapters_list)}-{max(chapters_list)}ç« ",
                    'suggestion': f"å»ºè®®æ£€æŸ¥{trait}çš„ä¸€è‡´æ€§ï¼Œç¡®ä¿å˜åŒ–åˆç†æˆ–æœ‰æ˜ç¡®çš„æƒ…èŠ‚æ”¯æ’‘"
                })

        return inconsistencies

# ============== ä¾¿æ·å‡½æ•° ==============

def run_coherence_check(novel_project_path: str, chapters: List[str], llm_config: Dict[str, Any]) -> Tuple[CoherenceScore, List[CoherenceIssue], str]:
    """
    è¿è¡Œè¿è´¯æ€§æ£€æŸ¥çš„ä¾¿æ·å‡½æ•°

    Args:
        novel_project_path: å°è¯´é¡¹ç›®è·¯å¾„
        chapters: ç« èŠ‚å†…å®¹åˆ—è¡¨
        llm_config: LLMé…ç½®

    Returns:
        Tuple[åˆ†æ•°å¯¹è±¡, é—®é¢˜åˆ—è¡¨, è´¨é‡æŠ¥å‘Š]
    """
    checker = CoherenceChecker(llm_config)
    return checker.run_coherence_check(chapters)